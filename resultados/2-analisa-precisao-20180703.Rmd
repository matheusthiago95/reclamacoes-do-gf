---
title: "Análise da precisão"
output: html_notebook
---

```{r}
library(tidyverse)
library(here)
library(modelr)
library(broom)

theme_set(theme_bw())
```

## Os dados

```{r carrega}

reclamacoes = read_csv(here("data/3-avaliacao-humana/reclamacoes-avaliadas-20190515.csv"))
sentimentos = read_csv(here("code/data/sentimento.csv"))

reclamacoes = reclamacoes %>% mutate(comprimento_reclamacao = str_length(texto))
```

`reclamacoes_l` tem um formato long em vez de wide (explicado [aqui](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/)).

```{r junta}
reclamacoes = reclamacoes %>% 
    left_join(sentimentos, by = "id")

reclamacoes_l = reclamacoes %>%  
    select(-palavras_op30, -palavras_sent, -'Grupo que vai avaliar') %>% 
    gather(key = "lexico", 
           value = "polaridade", 
           sentimento_op30, sentimento_sent)

reclamacoes_l %>% View()

```

Converte polaridades para escala 0-5

```{r}
# Faça você mesmo. Crie a variável polaridade_normalizada
reclamacoes_l = reclamacoes_l %>% 
     group_by(lexico) %>% mutate(polaridade_normalizada = round(((4 * (polaridade - max(polaridade))) / (min(polaridade) - max(polaridade))) + 1))
```

Calcula o erro (SSE) por reclamação

```{r}
reclamacoes_l = reclamacoes_l %>% 
    mutate(erro = (insatisfacao - polaridade_normalizada)**2)
```
```{r}
mediana <- median(x = reclamacoes_l$insatisfacao)
message("Médiana de insatisfação: ", mediana)
```
```{r}
filtroReclamacoes = reclamacoes_l %>% select(id_reclamacao = id, Insatisfação = insatisfacao, Polaridade = polaridade, Polaridade_Normalizada = polaridade_normalizada, Palavras = palavras, Comprimento = comprimento_reclamacao, Lexico = lexico, Erro = erro)
```

```{r}
LexicoSent = filtroReclamacoes %>% filter(Lexico == 'sentimento_sent')
LexicoOp30 = filtroReclamacoes %>% filter(Lexico == 'sentimento_op30')
LexicoSent = LexicoSent[order(LexicoSent$id_reclamacao),]
sLexicoOp30 = LexicoOp30[order(LexicoOp30$id_reclamacao),]
# reclamação x Polaridade normalizada
barplot(LexicoSent$Polaridade_Normalizada, 
        main="Nível de insatisfação - Sent",
        xlab=LexicoSent$id_reclamacao, 
        names.arg = LexicoSent$id_reclamacao
)
barplot(LexicoOp30$Polaridade_Normalizada,
        main="Nível de insatisfação - Op30",
        xlab=LexicoOp30$id_reclamacao,
        names.arg = LexicoOp30$id_reclamacao
)
```


```{r}
  ggplot(reclamacoes_l %>% filter(!is.na(polaridade_normalizada))) +
    geom_bar(mapping = aes(x = polaridade_normalizada)) + labs(title = "Avaliação a partir dos léxicos" , x = "Grau de Insatisfação", y = "Quantidade de Reclamações")
```
```{r}

ggplot(reclamacoes_l %>% filter(!is.na(insatisfacao))) +
    geom_bar(mapping = aes(x = insatisfacao)) + labs(title = "Avaliação partindo do experimento humano" , x = "Grau de Insatisfação", y = "Quantidade de Reclamações")
```
## EDA

Inicial. Faça os gráficos a mais que achar necessário para entender os dados que temos de resultado. Lembrando de nossa questão: Quão eficazes são os métodos de análise de sentimento baseados em léxicos para estimar o nível de insatisfação de reclamações recebidas pelo reclameaqui do governo federal? Existe um exemplo de EDA no repositório. Uma decisão importante a ser usada é se vamos considerar as avaliações humanas onde houve muita discordância sobre o nível de insatisfação.

###Como avaliar a eficácia dos métodos?  
Uma medida interessante da eficiência desses métodos é calcular a soma dos erros ao quadrado (SSE) considerando o que o método definiu como a polaridade_normalizada e o que a avaliação humana definiu como a insatisfação.

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30, y = sentimento_sent)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

```{r}
reclamacoes_l %>% 
    ggplot(aes(x = insatisfacao, y = polaridade_normalizada, group = insatisfacao)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_jitter(alpha = .7)  + 
    facet_wrap(~ lexico)

reclamacoes_l %>% 
    ggplot(aes(x = insatisfacao, y = erro, group = insatisfacao)) + 
    geom_jitter(alpha = .5)  +
    # geom_boxplot() + 
    facet_wrap(~ lexico)
```


## Há relação entre o léxico e o erro?

Agora um modelo para responder sua pergunta.

```{r}
#Cria variável dummy para preditor categórico
reclamacoes_l = reclamacoes_l %>% mutate(lexico.dummy = if_else(lexico == "sentimento_sent", 1, 0))
#Você precisa entender o que fez acima para interpretar sua regressão
#Você pode também criar uma variável dummy para o órgao (se anac ou inss)

# ggpairs(reclamacoes_l %>% select(<selecione as colulas que vc quer usar aqui>))
# lm1 = lm(<seu modelo>)
```

**Dica** - o texto de resultado que queremos produzir é algo como: 

Regressão múltipla foi utilizada para analisar se VarIndep1 e VarIndep2 tem uma associação significativa com o erro na estimativa de instatisfação da reclemação. Os resultados da regressão indicam que um modelo com os 2 preditores no formato Erro = XXX.VarIndep1 + YYY.VarIndep2 explicam XX,XX% da variância da variável de resposta (R2 = XX,XX). VarIndep1, medida como/em [unidade ou o que é o 0 e o que é 1] tem uma relação significativa com o erro (b = [yy,yy;  zz,zz], IC com 95%), assim como VarIndep2 medida como [unidade ou o que é o 0 e o que é 1] (b = [yy,yy;  zz,zz], IC com 95%). O aumento de 1 unidade de VarIndep1 produz uma mudança de...


#Regressão linear multipla
```{r}
y = reclamacoes$insatisfacao
op30 = LexicoOp30$Polaridade_Normalizada
sents = LexicoSent$Polaridade_Normalizada
regressao = lm(y ~ 
                 op30 +
                 sents
)
summary(regressao)
```

#Anova e Teste de normalidade
```{r}
anova = aov(y ~ op30 + sents)
summary(anova)

shapiro.test(resid(anova))
```


```{r}
view(reclamacoes_l)
```
```
